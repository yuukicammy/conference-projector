[
    {
        "url": "https://openaccess.thecvf.com/content/CVPR2023/html/Ci_GFPose_Learning_3D_Human_Pose_Prior_With_Gradient_Fields_CVPR_2023_paper.html",
        "pdf_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Ci_GFPose_Learning_3D_Human_Pose_Prior_With_Gradient_Fields_CVPR_2023_paper.pdf",
        "arxiv_id": "2212.08641",
        "title": "GFPose: Learning 3D Human Pose Prior With Gradient Fields",
        "abstract": "Learning 3D human pose prior is essential to human-centered AI. Here, we present GFPose, a versatile framework to model plausible 3D human poses for various applications. At the core of GFPose is a time-dependent score network, which estimates the gradient on each body joint and progressively denoises the perturbed 3D human pose to match a given task specification. During the denoising process, GFPose implicitly incorporates pose priors in gradients and unifies various discriminative and generative tasks in an elegant framework. Despite the simplicity, GFPose demonstrates great potential in several downstream tasks. Our experiments empirically show that 1) as a multi-hypothesis pose estimator, GFPose outperforms existing SOTAs by 20% on Human3.6M dataset. 2) as a single-hypothesis pose estimator, GFPose achieves comparable results to deterministic SOTAs, even with a vanilla backbone. 3) GFPose is able to produce diverse and realistic samples in pose denoising, completion and generation tasks.",
        "image_path": "test/top_images/0000.png",
        "description_en": "Learning 3D human pose prior is essential to human-centered AI. Here, we present GFPose, a versatile framework to model plausible 3D human poses for various applications. At the core of GFPose is a time-dependent score network, which estimates the gradient on each body joint and progressively denoises the perturbed 3D human pose to match a given task specification. During the denoising process, GFPose implicitly incorporates pose priors in gradients and unifies various discriminative and generative tasks in an elegant framework. Despite the simplicity, GFPose demonstrates great potential in several downstream tasks.",
        "advantages_en": "Our experiments empirically show that 1) as a multi-hypothesis pose estimator, GFPose outperforms existing SOTAs by 20% on Human3.6M dataset. 2) as a single-hypothesis pose estimator, GFPose achieves comparable results to deterministic SOTAs, even with a vanilla backbone. 3) GFPose is able to produce diverse and realistic samples in pose denoising, completion and generation tasks.",
        "essence_en": "At the core of GFPose is a time-dependent score network, which estimates the gradient on each body joint and progressively denoises the perturbed 3D human pose to match a given task specification. During the denoising process, GFPose implicitly incorporates pose priors in gradients and unifies various discriminative and generative tasks in an elegant framework.",
        "results_en": "Our experiments empirically show that 1) as a multi-hypothesis pose estimator, GFPose outperforms existing SOTAs by 20% on Human3.6M dataset. 2) as a single-hypothesis pose estimator, GFPose achieves comparable results to deterministic SOTAs, even with a vanilla backbone. 3) GFPose is able to produce diverse and realistic samples in pose denoising, completion and generation tasks.",
        "category_en": "3D Human Pose Estimation",
        "application_en": "Human-centered AI",
        "description_ja": "3D人物姿勢の事前学習は、人間中心のAIにとって重要です。ここでは、さまざまなアプリケーションのために、現実的な3D人物姿勢をモデル化するための汎用フレームワークであるGFPoseを提案します。GFPoseの中核には、時間依存のスコアネットワークがあり、各ボディジョイントの勾配を推定し、摂動を受けた3D人物姿勢を進行的にノイズ除去して、与えられたタスク仕様に一致させます。ノイズ除去の過程で、GFPoseは勾配に姿勢の事前知識を暗黙的に組み込み、優れたフレームワークでさまざまな識別的および生成的タスクを統一します。シンプルさにもかかわらず、GFPoseはいくつかの下流タスクで大きなポテンシャルを示しています。",
        "advantages_ja": "私たちの実験は次のように示しています。1）多重仮説姿勢推定器として、GFPoseはHuman3.6Mデータセットで既存のSOTAを20％上回ります。2）単一仮説姿勢推定器として、GFPoseはバニラバックボーンでも決定論的なSOTAと比較可能な結果を達成します。3）GFPoseは、姿勢のノイズ除去、補完、生成タスクで多様で現実的なサンプルを生成することができます。",
        "essence_ja": "GFPoseの中核には、時間依存のスコアネットワークがあり、各ボディジョイントの勾配を推定し、摂動を受けた3D人物姿勢を進行的にノイズ除去して、与えられたタスク仕様に一致させます。ノイズ除去の過程で、GFPoseは勾配に姿勢の事前知識を暗黙的に組み込み、優れたフレームワークでさまざまな識別的および生成的タスクを統一します。",
        "results_ja": "私たちの実験は次のように示しています。1）多重仮説姿勢推定器として、GFPoseはHuman3.6Mデータセットで既存のSOTAを20％上回ります。2）単一仮説姿勢推定器として、GFPoseはバニラバックボーンでも決定論的なSOTAと比較可能な結果を達成します。3）GFPoseは、姿勢のノイズ除去、補完、生成タスクで多様で現実的なサンプルを生成することができます。",
        "category_ja": "3D人物姿勢推定",
        "application_ja": "人間中心のAI",
        "award": ""
    },
    {
        "url": "https://openaccess.thecvf.com/content/CVPR2023/html/Xu_CXTrack_Improving_3D_Point_Cloud_Tracking_With_Contextual_Information_CVPR_2023_paper.html",
        "pdf_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Xu_CXTrack_Improving_3D_Point_Cloud_Tracking_With_Contextual_Information_CVPR_2023_paper.pdf",
        "arxiv_id": "2211.08542",
        "title": "CXTrack: Improving 3D Point Cloud Tracking With Contextual Information",
        "abstract": "3D single object tracking plays an essential role in many applications, such as autonomous driving. It remains a challenging problem due to the large appearance variation and the sparsity of points caused by occlusion and limited sensor capabilities. Therefore, contextual information across two consecutive frames is crucial for effective object tracking. However, points containing such useful information are often overlooked and cropped out in existing methods, leading to insufficient use of important contextual knowledge. To address this issue, we propose CXTrack, a novel transformer-based network for 3D object tracking, which exploits ConteXtual information to improve the tracking results. Specifically, we design a target-centric transformer network that directly takes point features from two consecutive frames and the previous bounding box as input to explore contextual information and implicitly propagate target cues. To achieve accurate localization for objects of all sizes, we propose a transformer-based localization head with a novel center embedding module to distinguish the target from distractors. Extensive experiments on three large-scale datasets, KITTI, nuScenes and Waymo Open Dataset, show that CXTrack achieves state-of-the-art tracking performance while running at 34 FPS.",
        "image_path": "test/top_images/0001.png",
        "description_en": "3D single object tracking plays an essential role in many applications, such as autonomous driving. It remains a challenging problem due to the large appearance variation and the sparsity of points caused by occlusion and limited sensor capabilities. Therefore, contextual information across two consecutive frames is crucial for effective object tracking. However, points containing such useful information are often overlooked and cropped out in existing methods, leading to insufficient use of important contextual knowledge. To address this issue, we propose CXTrack, a novel transformer-based network for 3D object tracking, which exploits ConteXtual information to improve the tracking results. Specifically, we design a target-centric transformer network that directly takes point features from two consecutive frames and the previous bounding box as input to explore contextual information and implicitly propagate target cues. To achieve accurate localization for objects of all sizes, we propose a transformer-based localization head with a novel center embedding module to distinguish the target from distractors. Extensive experiments on three large-scale datasets, KITTI, nuScenes and Waymo Open Dataset, show that CXTrack achieves state-of-the-art tracking performance while running at 34 FPS.",
        "advantages_en": "CXTrack improves 3D point cloud tracking by effectively utilizing contextual information. It addresses the issue of overlooking and cropping out points containing useful contextual knowledge in existing methods. The proposed transformer-based network achieves state-of-the-art tracking performance on three large-scale datasets.",
        "essence_en": "The key essence of CXTrack is the exploitation of contextual information in 3D object tracking. It uses a target-centric transformer network to explore contextual information and implicitly propagate target cues. Additionally, a transformer-based localization head with a center embedding module is used for accurate localization of objects.",
        "results_en": "Extensive experiments on three large-scale datasets, KITTI, nuScenes and Waymo Open Dataset, show that CXTrack achieves state-of-the-art tracking performance while running at 34 FPS.",
        "category_en": "3D Object Tracking",
        "application_en": "Autonomous driving",
        "description_ja": "3Dシングルオブジェクトトラッキングは、自動運転など多くのアプリケーションで重要な役割を果たしています。外観の大きな変動や、遮蔽物やセンサの制約による点のまばらさなどの問題により、依然として困難な課題です。そのため、連続する2つのフレーム間のコンテキスト情報は、効果的なオブジェクトトラッキングにおいて重要です。しかし、このような有用な情報を含む点は、既存の手法ではしばしば見落とされ、切り取られてしまい、重要なコンテキスト知識の不十分な利用につながります。この問題を解決するために、私たちはCXTrackを提案します。これは、3Dオブジェクトトラッキングのための新しいトランスフォーマーベースのネットワークであり、コンテキスト情報を利用してトラッキング結果を改善します。具体的には、ターゲット中心のトランスフォーマーネットワークを設計し、連続する2つのフレームと前のバウンディングボックスからポイント特徴を直接入力として使用し、コンテキスト情報を探索し、ターゲットの手がかりを暗黙的に伝播させます。さらに、オブジェクトの正確な位置特定を実現するために、トランスフォーマーベースの位置特定ヘッドと、ターゲットと他の物体を区別するための新しいセンター埋め込みモジュールを提案します。KITTI、nuScenes、Waymo Open Datasetの3つの大規模データセットでの詳細な実験結果は、CXTrackが34FPSで動作しながら最先端のトラッキング性能を達成していることを示しています。",
        "advantages_ja": "CXTrackは、コンテキスト情報を効果的に活用することで、3Dポイントクラウドトラッキングを改善します。既存の手法では有用なコンテキスト知識を含む点を見落としたり切り取ったりする問題に対処しています。提案されたトランスフォーマーベースのネットワークは、3つの大規模データセットで最先端のトラッキング性能を達成しています。",
        "essence_ja": "CXTrackのキーポイントは、3Dオブジェクトトラッキングにおけるコンテキスト情報の活用です。ターゲット中心のトランスフォーマーネットワークを使用してコンテキスト情報を探索し、ターゲットの手がかりを暗黙的に伝播させます。さらに、オブジェクトの正確な位置特定のために、トランスフォーマーベースの位置特定ヘッドとセンター埋め込みモジュールを使用します。",
        "results_ja": "KITTI、nuScenes、Waymo Open Datasetの3つの大規模データセットでの詳細な実験結果は、CXTrackが34FPSで動作しながら最先端のトラッキング性能を達成していることを示しています。",
        "category_ja": "3D物体追跡",
        "application_ja": "自動運転",
        "award": ""
    },
    {
        "url": "https://openaccess.thecvf.com/content/CVPR2023/html/Lin_Deep_Frequency_Filtering_for_Domain_Generalization_CVPR_2023_paper.html",
        "pdf_url": "https://openaccess.thecvf.com/content/CVPR2023/papers/Lin_Deep_Frequency_Filtering_for_Domain_Generalization_CVPR_2023_paper.pdf",
        "arxiv_id": "2203.12198",
        "title": "Deep Frequency Filtering for Domain Generalization",
        "abstract": "Improving the generalization ability of Deep Neural Networks (DNNs) is critical for their practical uses, which has been a longstanding challenge. Some theoretical studies have uncovered that DNNs have preferences for some frequency components in the learning process and indicated that this may affect the robustness of learned features. In this paper, we propose Deep Frequency Filtering (DFF) for learning domain-generalizable features, which is the first endeavour to explicitly modulate the frequency components of different transfer difficulties across domains in the latent space during training. To achieve this, we perform Fast Fourier Transform (FFT) for the feature maps at different layers, then adopt a light-weight module to learn attention masks from the frequency representations after FFT to enhance transferable components while suppressing the components not conducive to generalization. Further, we empirically compare the effectiveness of adopting different types of attention designs for implementing DFF. Extensive experiments demonstrate the effectiveness of our proposed DFF and show that applying our DFF on a plain baseline outperforms the state-of-the-art methods on different domain generalization tasks, including close-set classification and open-set retrieval.",
        "image_path": "test/top_images/0002.png",
        "description_en": "Improving the generalization ability of Deep Neural Networks (DNNs) is critical for their practical uses, which has been a longstanding challenge. Some theoretical studies have uncovered that DNNs have preferences for some frequency components in the learning process and indicated that this may affect the robustness of learned features. In this paper, we propose Deep Frequency Filtering (DFF) for learning domain-generalizable features, which is the first endeavour to explicitly modulate the frequency components of different transfer difficulties across domains in the latent space during training. To achieve this, we perform Fast Fourier Transform (FFT) for the feature maps at different layers, then adopt a light-weight module to learn attention masks from the frequency representations after FFT to enhance transferable components while suppressing the components not conducive to generalization. Further, we empirically compare the effectiveness of adopting different types of attention designs for implementing DFF. Extensive experiments demonstrate the effectiveness of our proposed DFF and show that applying our DFF on a plain baseline outperforms the state-of-the-art methods on different domain generalization tasks, including close-set classification and open-set retrieval.",
        "advantages_en": "The proposed Deep Frequency Filtering (DFF) approach explicitly modulates the frequency components of different transfer difficulties across domains, which improves the generalization ability of Deep Neural Networks (DNNs). The approach enhances transferable components while suppressing the components not conducive to generalization, resulting in improved robustness of learned features. The effectiveness of DFF is demonstrated through extensive experiments, outperforming state-of-the-art methods on different domain generalization tasks.",
        "essence_en": "The key essence of the proposed approach is the Deep Frequency Filtering (DFF) technique, which modulates the frequency components of different transfer difficulties across domains in the latent space during training. DFF performs Fast Fourier Transform (FFT) on the feature maps and learns attention masks from the frequency representations to enhance transferable components and suppress non-generalizable components.",
        "results_en": "Extensive experiments show that the proposed Deep Frequency Filtering (DFF) approach outperforms state-of-the-art methods on different domain generalization tasks, including close-set classification and open-set retrieval. The effectiveness of DFF is demonstrated in improving the generalization ability of Deep Neural Networks (DNNs) and enhancing the robustness of learned features.",
        "category_en": "Domain Generalization",
        "application_en": "Improving the generalization ability of Deep Neural Networks (DNNs) in various computer vision tasks, such as image classification, object detection, and semantic segmentation.",
        "description_ja": "Deep Neural Networks（DNN）の汎化能力を向上させることは、実用化において重要であり、長年の課題となっています。一部の理論的な研究では、DNNが学習プロセスで特定の周波数成分を好む傾向があり、これが学習された特徴の堅牢性に影響を与える可能性があることが示されています。本論文では、ドメイン汎化可能な特徴を学習するためのDeep Frequency Filtering（DFF）を提案しています。これは、トレーニング中に潜在空間で異なる転送難易度の周波数成分を明示的に調整する最初の試みです。これを実現するために、異なるレイヤーの特徴マップに対して高速フーリエ変換（FFT）を実行し、FFT後の周波数表現から注意マスクを学習する軽量モジュールを採用して、転送可能な成分を強化し、汎化に適さない成分を抑制します。さらに、異なるタイプの注意デザインを採用した場合のDFFの効果を経験的に比較します。大規模な実験により、提案されたDFFの効果が示され、プレーンなベースラインにDFFを適用することで、クローズセット分類やオープンセット検索などの異なるドメイン汎化タスクで、最先端の手法を上回る性能が得られます。",
        "advantages_ja": "提案されたDeep Frequency Filtering（DFF）手法は、異なるドメイン間での転送難易度の周波数成分を明示的に調整することで、Deep Neural Networks（DNN）の汎化能力を向上させます。この手法は、転送可能な成分を強化し、汎化に適さない成分を抑制することで、学習された特徴の堅牢性を向上させます。DFFの効果は、大規模な実験によって示され、異なるドメイン汎化タスクで最先端の手法を上回る性能が得られます。",
        "essence_ja": "提案手法のキーポイントは、トレーニング中に異なるドメイン間での転送難易度の周波数成分を潜在空間で調整するDeep Frequency Filtering（DFF）テクニックです。DFFは、特徴マップに対して高速フーリエ変換（FFT）を実行し、周波数表現から注意マスクを学習して、転送可能な成分を強化し、汎化に適さない成分を抑制します。",
        "results_ja": "大規模な実験により、提案されたDeep Frequency Filtering（DFF）手法が、クローズセット分類やオープンセット検索などの異なるドメイン汎化タスクで最先端の手法を上回ることが示されました。DFFの効果は、Deep Neural Networks（DNN）の汎化能力の向上と学習された特徴の堅牢性の向上を実証しています。",
        "category_ja": "ドメイン汎化",
        "application_ja": "画像分類、物体検出、セマンティックセグメンテーションなど、さまざまなコンピュータビジョンタスクにおけるDeep Neural Networks（DNN）の汎化能力の向上",
        "award": ""
    }
]